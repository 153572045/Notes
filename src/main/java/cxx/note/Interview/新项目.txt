


面试官好，我叫陈潇贤，目前在宝洁中国IT部做JAVA开发，在这边主要的工作有运维自动化平台，企微代理网关等项目的设计和开发，还有一些基础应用的迭代维
护，用到的技术包括了spring mysql redis等，然后之前是在京东推荐架构部做过推荐引擎开发，在那边的主要工作有 一些新推荐位的开发和维护，架构迁移，
算子和模块重构等。
------------------------------------------------------------------------------------------------------------------------
企微代理网关
之前我们这边的办公平台是微软的teams，后面为了方便才开通了企业微信， 相应的就会有一些应用想在企微上做一些自建应用，他们需要去调用企微的一些接口，调
用企微的接口需要一些令牌token,secret等信息，如果将这些信息都给了应用，他们实际上可以去调任意接口，这种行为很不安全
为了做更细力度的权限控制，我们就搞了一个中间的代理网关，这样应用想调用企微的接口，就需要通过网关去调用，他们能调用哪些接口完全受到网关的限制
，无法任意调，实现了按需分配调用权限的功能，而且我们也可以很方便的对这些调用行为去做监控，流量限制。
也提供了一些消息订阅服务和分发功能

运维自动化平台
这是一个比较大的平台，我在里面主要是做了一个运维工单处理模块，运维工单就是我们平时要发布变更就需要提变更单，有事故就要提Incident事故单，然后由相
关的领导或者应用团队去处理，其实这些工作流的功能jira就能做，但是我们领导觉得jira用起来不够方便，所以这个模块是在jira的基础上做的一个封装，增加了
类似一键拉会、告警、协助Incident快速定级等 额外功能
------------------------------------------------------------------------------------------------------------------------
推荐引擎是京东推荐流程的一个驱动引擎，我简单说一下推荐的基本流程 一个基本的推荐流程一般是包括了四个环节，即取数
商品召回，商品排序，还有业务调控，
1、第一个环节取数就是去获取用户的画像信息、行为信息等数据   个性化
2、有了用户信息后就可以做商品召回了，商品召回就是从不同的商品底池里面去捞数据，因为不同的推荐位背后的商品底池是不一样的，每个底池中的数据可能有几百万
甚至几千万，召回就是通过某种策略快速从对应的底池里捞出一小部分数据
3、商品召回后可能会有几百个或一两千个商品，所以需要排序
4、排完序后再经过一系列业务调控，比如说过滤，打散等
这就是推荐的一个基本流程。

我们的系统就是这个流程的一个驱动引擎，以上说的推荐流程的四个环节，都会有一个专门的部门在做，然后对外提供服务，我们的引擎系统是推荐的入口服务，当一个请求打进我们
系统的时候，我们会去调取数服务获取用户信息，再封装这些数据去调用召回服务，召回服务会根据我们的入参给我们返回召回商品，我们再将以这些商品结合其他参数去调
排序服务，排序服务对这些商品进行排序打分后再给我们返回，最后我们会做业务调控，再返回结果给上游服务。 这是我以最简的方式去介绍我们的系统功能

真实的过程是很复杂的，因为对于每一个环节，内部的逻辑是很多很复杂的，当然像召回和排序的复杂性主要承接在别的服务上，而我们系统的复杂性是抽象和复用性的问题
，因为整个京东推荐都会走我们的系统，每个具体的推荐位的具体逻辑都不一样，虽然说它们的流程架构都是这几个环节，但是每个环节的内部逻辑都是有差异的，就拿
商品召回来说，不同推荐位的召回策略是不一样的，有的是根据热门商品进行相关召回或相似召回，有的根据用户的点击行为进行召回，有的根据购买行为进行召回。
就单单京东商城这个平台来说，就有六七百个推荐位，这意味着有几百个不同的流程管道需要开发和维护，这种工作量显然是巨大的，特别是业务调控环节，主要在我们系统中实现

所以说我们系统的第一个挑战点就是复用性问题，复用性高意味着可以提高我们的开发效率，另一个就是性能了，怎么保证一个推荐流程能够在一两百毫秒的时间内完成

推荐流程的每个环节涉及到的业务逻辑都很多，而且很杂，所以我们是将一个大环节进行抽象，并切割成许多子流程，在代码实现的时候每个子流程就对应一个处理器，也叫处理
算子，就像netty的pipline里面的Handler一样，每个处理算子承接一小部分业务逻辑，将这些处理算子进行编排，就能构成一个大的流程环节。这样能达到的效果就是，只要
你的子流程处理算子抽象得够好，开发一个推荐位几乎可以仅仅通过编排这些算子以及配置他们的参数来实现，甚至不用进行代码开发，也就是说不同的推荐位共用一套代码。
这样能大大提高开发和维护效率。



树引擎

在对这些处理算子开发完成后，我们将一次完整的推荐流程用一颗树或者是一个图来描述，用hocon这种数据格式在配置文件上进行描述，之后每一个请求进来，我们都会
找到相应的配置文件，然后将这个配置文件解析成一个配置对象，将整棵树的信息封装在一个配置对象里面，这个配置对象包含了根节点的配置信息，因为树是一种递归
的数据结构，这也意味着根节点实际上包含了整棵树的信息。
执行的时候从根节点开始解析执行，


树引擎需要我们在配置文件上去指定各个处理算子的执行顺序，执行方式，哪些节点能并发执行，哪些不能， 一个推荐流程涉及到的处理算子有几十个，大推荐位有几百
个，这对于后期的维护工作还是比较困难的，而图仅仅需要配置哪些节点依赖于那些数据，每个节点会产出什么数据，不需要去关心他们的执行顺序以及执行方式，图引擎
会以数据依赖为驱动的执行方式，实现自动化最优并发执行的效果，也就是说当某个节点的依赖数据就绪，会立即被丢到线程里面去执行


遇到线上问题
遇到过一次比较棘手的线上问题， 有一次算法团队那边向我们反映我们组负责的一个推荐位的tp99延迟从200ms涨到300ms，然后我就去排查，首先我通过监控找到延
迟上涨的具体时刻，然后去检查当天的代码，看看有没有异常的地方，看完代码后没有发现有异常，至少没看到很直观的异常代码，所以只能去回滚代码，然后将回滚后
的代码部署到测试机上进行测试，因为我们系统每天提交的代码量也比较杂，所以只能一步步进行回滚测试。
就这样回滚测试搞了大半天，还是没找到原因，回滚后延迟依然是很高，然后我就考虑有可能是其他服务引起的，不是我们这边系统的问题，就去看其他系统的监控，
一开始也没看出有什么异常的地方。后来从别的系统监控中观察到，一些系统在某一天的延迟突然平稳地下降，然后隔了好几天后又平稳地突然上涨，这个上涨的点刚好和
我们系统异常的时间点重合了，经过分析后才意识到前段时间是为了应付年货节，对机器进行了扩容，活动过后又进行了缩容，而这个异常可能被这个扩容效果给掩盖掉了，
等到扩容结束后才暴露出问题，所以我就把时间线回滚到扩容之前的代码，结果延迟确实也降下来了，后面针对那部分代码，通过阿尔萨斯不断去采样生成火焰图，找到
其中一个取数节点的延迟忽高忽低，才找到问题所在。 结果确实是其他服务的问题


高可用
1、集群的搭建上，因为我们的流量比较大，总共有三千多台机器在运行我们的系统，加机器也是提高可用性的一种策略，另一个是我们根据推荐位的重要程度和复杂程度
分配不同的资源，对于首页为你推荐这种大推荐位，我们专门用一个集群去处理，同时采用专门的限流策略，因为执行一次复杂的推荐流程需要的资源更多，单机吞吐量差
距很大，以此来尽量保证重要推荐位的可用性和性能

2、在代码架构的设计上，我们对不同业务类型的处理算子进行分类，实现的时继承自同一个接口，同一个抽象类，处理算子的通用流程在抽象类中实现，并以抽象模板方法
的方式去扩展各自的功能，这样就可以在抽象类中很方便地去做一些统一的异常处理或兜底工作，尽可能减少了整条数据链路因为某个处理算子有异常或者拿不到数据导致
整条链路出不了数据的情况。当然，因为我们系统的特点，在一些重要节点如果拿不到数据或者出现异常，也会最终出不了结果，比如说在召回阶段，有可能网络超时原因
或者那边服务不可用的原因导致我们这边拿不到数据，所以我们每次推荐都会用多个算子去并发调用多路召回服务，即使其中某路出了问题，也有一些冷启的召回进行兜底，
不会说出现空结果。
排序分片  分摊风险
上有服务若个性化兜底

3、 有降级 限流 和熔断等策略来保证我们系统的稳定性和安全