
Kafka的使用场景

1、日志收集
2、消息系统
3、用户活动追踪
4、运营指标

------------------------------------------------------------------------------------------------------------------------
一、Kafka的三大元素

1、消息的生产者(Producer)
可以向指定的Topic内发送消息(目前的理解是 一个Producer往一个topic发消息，会hash映射到一个partition)
执行一个命令(指定topic)后可以打开一个客户端，然后输入消息，就会往kafka发送消息

2、kafka消息队列(Broker,消息中间件处理节点，一个Kafka节点就是一个broker，一个或多个broker可以组成一个kafka集群)
可以通过kafka命令(或者Java代码)向zk中建立一个topic，需指定分区数和副本数，还有zk地址，创建完成后可以去zk里面看有哪些topic，zk只保存主题，
消息数据保存在kafka(保存在某个topic目录下的log文件中，即每个topic的每个分区都有一个log文件)，
消息的保存是有序的，通过offset来描述消息的有序性
消费者消费消息也是有序的

3、消息的消费者(Consumer)
通过订阅某个Topic来获取消息(只要订阅了一个topic，不管有多少个分区，都能被一个消费组内的消费者消费到)
默认从连接后的最后一条信息的偏移量+1开始消息，也可以指定从头消费
------------------------------------------------------------------------------------------------------------------------
单播和多播

单播
若多个消费者在同一个消费组内，只有一个消费者可以收到订阅的topic消息，即同一个消费组中只有一个消费者可以收到一个topic中的消息
，消费组在启动消费者客户端的命令中指定

多播
不同的消费组订阅同一个topic，不同的消费组中只有一个消费者能收到消息，也就是多个消费组中的多个消费者可以收到消息
------------------------------------------------------------------------------------------------------------------------
./kafka-consumer-groups.sh --bootstrap-server id:端口 --describe --group 消费组名
该命令可以看到消费组的详细信息，比如有订阅的主题信息，最大偏移量以及已消费的偏移量，积压的消息等信息

------------------------------------------------------------------------------------------------------------------------
主题和分区的概念

1、主题Topic
topic在kafka中是一个逻辑概念，kafka通过topic将消息进行分类，不同的topic会被订阅该topic的消费者消费
当topic中的消息非常多，因为消息会被保存在log日志文件中，为了解决文件过大的问题，kafka提出了Partition分区概念
分区可以实现分布式存储，可以实现并行写，提高读写的吞吐量

通过partition将一个topic中的消息分区来存储，这样的好处有
1、分区存储，可以解决统一存储文件过大的问题
2、提高读写的吞吐量，即读写可以同时在多个分区中进行

为同一个主题创建多个分区：
./kafka-topics.sh --create --zookeeper localhost:2181 --partions 2 --topic test1

./kafka-topics.sh --list --zookeeper localhost:2128  查看当前zk中所有主题
------------------------------------------------------------------------------------------------------------------------
副本的概念
副本是对主题分区的备份，目的是实现高可用，在集群中，不同的副本会被部署到不同的broker上，下面命令可以创建1个主题，2个分区，3个副本
./kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 3 --partitions 2 --topic my-replicated-topic

副本是为了为主题中的分区创建多个备份，多个副本放在kafka集群的多个broker中，会有一个副本作为Leader,其他是followr
leader:kafka的读写操作，都发生在leader上，同时leader负责把数据同步给folloer，当leader挂了，由controller重新从多个follower选举产生一个
新的leader，选举的原则是从该分区的isr中选取第一个。
follower:接受leader的同步数据

./kafka-topics.sh --describe --zookeeper hosthost:2181 --topic my-replicated-topic
可以看到topic的分区 以及各个分区的leader,Isr等信息
isr:可以同步的broker节点和已经同步的broker节点，存放在isr集合中，若某个broker效率太低，会被集群剔出isr，选举也是从isr中进行选举的
------------------------------------------------------------------------------------------------------------------------
消息日志文件中保存的内存
00000.log: 这种文件保存的就是消息
-consumer-offsets-49:
kafka内部自己创建了-consumer-offsets主题包含了50个分区，这个主题用来存放消费者消费某个主题的偏移量，在集群中，这个主题放在broker-0,也就是
controller上面，防止单节点故障，应该从配置文件进行配置，增加副本数(待了解)

工作原理：
消费者会定期(poll后消费完)就会将自己消费分区的offset提交给kafka内部的topic:_consumer_offsets,提交过去的时候，key是
consumerGroupid + topic + 分区号，value就是当前的offset，之后kafka会定期清理topic里面的消息，最后就保留最新的那条数据

因为_consumer_offsets可能会接受高并发的请求，为了提高这个主题的并发性，kafka默认给这个主题分配50个分区(可设置)，这样可以通过加机器的方式抗大并发
公式:hash(consumerGroupid) % _consumer_offsets主题分区数

有了consumer_offsets后，如果消费者宕机了，重启后就可以从原来的偏移量处开始消费
------------------------------------------------------------------------------------------------------------------------
集群的发送与消费
kafka只能在Partition的范围内保证消息消费的局部顺序性，不能在同一个topic中的多个partition中保证总的消费顺序性，一个消费者可以消费多个
partition
消费组中的消费者数量不能比一个topic中的partition数量多，否则多出来的消费者消费不到消息

一个partition只能被一个消费组中的一个消费者消费，目的是为了保证消费的顺序性，但是多个partition的多个消费者消费的总的顺序是得不到保证的
partition数量决定了消费组中消费者的数量，建议同一个消费组中消费者的数量不要超过partition数量，否则多的那些消费不到消息

------------------------------------------------------------------------------------------------------------------------
问题
1、为什么一个partition只能被一个消费组里的一个消费者消费？
答：为了保证消费的顺序性，比如有消息1，2，3， 如果消息1被消费者1消费，2被消费者2消费，但是消费者1由于性能或网络问题消费太慢，有可能2先被消费了
2、HW和LEO
LEO是某个副本最后消息的消息位置
HW俗称高水位，取一个partition对应的ISR中最小的LEO(log-end-offset)作为HW，consumer最多只能消费到HW所在的位置，
leader,follower各自负责更新自己的HW。对于leader写入数据后，consumer不能立即消费，leader会等待该消息被所有ISR中的replicas同步后更新HW，
此时消息才能被consumer消费，这样就保证了如果leader所在的broker失效，该消息仍然可以从新选举的leader中获取
3、如何防止消息丢失
生产者：1、使用同步发送2、ack配成1或all可以防止数据丢失，如果要做到99.999%，ack要用all并把设置同步分区数>2  从性能角度将 ack=1比较合理
消费者：把自动提交改成手动提交
4、解决重复消费
(1)、把重试关了，但是有可能会丢失消息
(2)、在消费者端解决幂等性消费问题，两种方案：1、在mysql表中创建一个联合主键 2、使用分布式锁，Redission.lock()
5、解决消息积压
出现的原因：消息的消费者的消费速度远赶不上生产者的生产消息速度，导致kafka中有大量的数据没有被消费，随着没有被消费的数据堆积越多，消费者寻址的性能
会越来越差，最后导致整个kafka对外提供服务的性能越来越差，从而造成其他服务也访问速度变慢，造成服务雪崩

解决方案
1、对消费者进行性能优化，比如说使用多线程或者从业务角度去提高消费速度
2、增加分区，然后增加消费者去并行消费
3、用一个中间消费者去拉消息，然后往另一个主题上去发消息，这个主题可以设置多个分区，然后用多个消费者去订阅这个主题进行消费


zk的作用
主要用于集群中不同节点间的通信，比如leader选举，配置管理，记录节点的状态等